<!DOCTYPE html>













<html class="theme-next muse" lang="zh-CN">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">










  <meta name="google-site-verification" content="HCj467TtuvFkAzzdCvYvbniAeNiUy7TUwp2hG1qGWQE">







  <meta name="baidu-site-verification" content="LppFIbSdZO">



  
  
    
  
  <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css">




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Monda:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext">
  






  

<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/font-awesome@4/css/font-awesome.min.css">

<link rel="stylesheet" href="/css/main.css?v=7.1.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.1.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.1.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.1.0">


  <link rel="mask-icon" href="/images/safari-pinned-tab.svg?v=7.1.0" color="#222">







  <script>
  (function(i,s,o,g,r,a,m){i["DaoVoiceObject"]=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;a.charset="utf-8";m.parentNode.insertBefore(a,m)})(window,document,"script",('https:' == document.location.protocol ? 'https:' : 'http:') + "//widget.daovoice.io/widget/3d64b7fd.js","daovoice")
  daovoice('init', {
      app_id: "64974cdc"
    });
  daovoice('update');
  </script>



<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '7.1.0',
    sidebar: {"position":"left","display":"always","offset":12,"onmobile":false,"dimmer":false},
    back2top: true,
    back2top_sidebar: false,
    fancybox: true,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":false,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"搜索文章内容","hits_empty":"无法找到相关结果: ${query}","hits_stats":"${time} ms 内匹配到 ${hits} 条结果"}
    }
  };
</script>

<script>
    (function () {
        if ('') {
            if (prompt('请输入文章密码') !== '') {
                alert('密码错误！');
                if (history.length === 1) {
                    location.replace("https://ligang-chn.github.io"); // 这里替换成你的首页
                } else {
                    history.back();
                }
            }
        }
    })();
</script>




  




  <meta name="description" content="​        聚类算法是一种典型的无监督算法，目的是依据已知数据，将相似度高的样本集中到各自的簇中。 ​        聚类算法可以实现数据分割，异常点的监控。所谓的异常点就是远离簇的样本，而这些样本可能就是某些场景下的关注点。 ​        聚类算法种类有：Kmeans聚类、K中心聚类、谱系聚类、EM聚类算法、基于密度的聚类和基于网格的聚类等。 ​        本文主要是Kmeans聚">
<meta name="keywords" content="Python,聚类,KMeans">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习—Kmeans聚类">
<meta property="og:url" content="https://ligang-chn.github.io/2019/10/03/Kmeans聚类/index.html">
<meta property="og:site_name" content="LiGang&#39;s Blog">
<meta property="og:description" content="​        聚类算法是一种典型的无监督算法，目的是依据已知数据，将相似度高的样本集中到各自的簇中。 ​        聚类算法可以实现数据分割，异常点的监控。所谓的异常点就是远离簇的样本，而这些样本可能就是某些场景下的关注点。 ​        聚类算法种类有：Kmeans聚类、K中心聚类、谱系聚类、EM聚类算法、基于密度的聚类和基于网格的聚类等。 ​        本文主要是Kmeans聚">
<meta property="og:locale" content="zh-CN">
<meta property="og:updated_time" content="2019-10-04T10:54:43.726Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="机器学习—Kmeans聚类">
<meta name="twitter:description" content="​        聚类算法是一种典型的无监督算法，目的是依据已知数据，将相似度高的样本集中到各自的簇中。 ​        聚类算法可以实现数据分割，异常点的监控。所谓的异常点就是远离簇的样本，而这些样本可能就是某些场景下的关注点。 ​        聚类算法种类有：Kmeans聚类、K中心聚类、谱系聚类、EM聚类算法、基于密度的聚类和基于网格的聚类等。 ​        本文主要是Kmeans聚">



  <link rel="alternate" href="/atom.xml" title="LiGang's Blog" type="application/atom+xml">



  
  
  <link rel="canonical" href="https://ligang-chn.github.io/2019/10/03/Kmeans聚类/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>机器学习—Kmeans聚类 | LiGang's Blog</title>
  












  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">LiGang's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
      
        <p class="site-subtitle">日拱一卒，功不唐捐</p>
      
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
    
      
    

    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>分类</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>标签</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-about">

    
    
    
      
    

    

    <a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i> <br>关于</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-album">

    
    
    
      
    

    

    <a href="/album/" rel="section"><i class="menu-item-icon fa fa-fw fa-camera-retro"></i> <br>相册</a>

  </li>

      
      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>搜索</a>
        </li>
      
    </ul>
  

  
    

  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



  



</div>
    </header>

    
  
  

  

  <a href="https://github.com/ligang-chn" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewbox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"/><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"/><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"/></svg></a>



    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://ligang-chn.github.io/2019/10/03/Kmeans聚类/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="小木子">
      <meta itemprop="description" content="拥抱月亮">
      <meta itemprop="image" content="/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LiGang's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">机器学习—Kmeans聚类

              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-10-03 10:17:23" itemprop="dateCreated datePublished" datetime="2019-10-03T10:17:23+08:00">2019-10-03</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-10-04 18:54:43" itemprop="dateModified" datetime="2019-10-04T18:54:43+08:00">2019-10-04</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/机器学习/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2019/10/03/Kmeans聚类/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2019/10/03/Kmeans聚类/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
            <span id="/2019/10/03/Kmeans聚类/" class="leancloud_visitors" data-flag-title="机器学习—Kmeans聚类">
              <span class="post-meta-divider">|</span>
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              
                <span class="post-meta-item-text">阅读次数：</span>
              
                <span class="leancloud-visitors-count"></span>
            </span>
          

          

          
            <div class="post-symbolscount">
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">本文字数：</span>
                
                <span title="本文字数">32k</span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">29 分钟</span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">
      
      
      

      
        <p>​        聚类算法是一种典型的无监督算法，目的是依据已知数据，将相似度高的样本集中到各自的簇中。</p>
<p>​        聚类算法可以实现数据分割，异常点的监控。所谓的异常点就是远离簇的样本，而这些样本可能就是某些场景下的关注点。</p>
<p>​        聚类算法种类有：Kmeans聚类、K中心聚类、谱系聚类、EM聚类算法、基于密度的聚类和基于网格的聚类等。</p>
<p>​        本文主要是Kmeans聚类，该算法利用距离远近的思想将目标数据聚为指定的k个簇，簇内样本越相似，表明聚类效果越好。簇中心点由各簇样本均值计算得到。</p>
<a id="more"></a>
<h3 id="Kmeans的思想"><a href="#Kmeans的思想" class="headerlink" title="Kmeans的思想"></a>Kmeans的思想</h3><p>​        该算法思路很简单，就是不断计算各样本点与簇中心之间的距离，直到<strong>所有簇内样本的离差平方和之和</strong>达到最小为止。具体步骤如下：</p>
<p>​        1）从数据中随机挑选k个样本点作为原始的簇中心；</p>
<p>​        2）计算剩余样本与簇中心的距离，并把各样本标记为离k个簇中心最近的类别；</p>
<p>​        3）重新计算各簇内样本点的均值，并以均值作为新的k个簇中心；</p>
<p>​        4）不断重复2）和3），直到簇的中心的变化趋于稳定，形成最终的k个簇。</p>
<h3 id="Kmeans的原理"><a href="#Kmeans的原理" class="headerlink" title="Kmeans的原理"></a>Kmeans的原理</h3><p>​        根据如上思想，可以将<strong>目标函数</strong>表示为：</p>
<script type="math/tex; mode=display">
J(c_1,c_2,...c_k)=\sum_{j=1}^{k}\sum_{i}^{n_j}(x_i-c_j)^2</script><p>​        其中，</p>
<p>​        $c_j$表示第$j$个簇的簇中心，</p>
<p>​        $x_i$属于第$j$个簇的样本$i$，</p>
<p>​        $n_j$表示第$j$个簇的样本总量。</p>
<p>​        即，在第$j$个簇内，计算其他样本点到簇中心的距离平方，然后将所有的距离平方累加求和（内层求和号），此时一个簇计算得到的是一个距离和值，最后将所有簇（$j$个簇）的距离和值再次累加求和（外层求和号），就是所有簇内样本的离差平方和之和。</p>
<p>​        对于上述目标函数，未知数是$c_j$，要想求目标函数的最小值，得先确定$c_j$的值。刚好目标函数是一个凸函数，可以通过求导的方式获取$c_j$的值。</p>
<p>​        第一步，对目标函数求偏导</p>
<script type="math/tex; mode=display">
\frac {\partial J}{\partial c_j}=\sum_{i=1}^{n_j}-2(x_i-c_j)</script><p>​        【注意】：由于这里仅对第$j$个簇中心求偏导，所以其他簇此时的偏导数均为0。</p>
<p>​        第二步，令导数为0</p>
<script type="math/tex; mode=display">
\sum_{i=1}^{n_j}-2(x_i-c_j)=0
\\
n_jc_j-\sum_{i=1}^{n_j}x_i=0
\\
c_j= \frac {\sum_{i=1}^{n_j}x_i}{n_j}=\mu_j</script><p>​        由此看出，<strong>只有当簇中心$c_j$为簇内样本的均值时，目标函数才会达到最小</strong>。这也是上面为什么用均值作为簇中心。</p>
<h3 id="K值确定"><a href="#K值确定" class="headerlink" title="K值确定"></a>K值确定</h3><p>​        前面都是基于已知的k个簇运算出最佳的簇中心，如果聚类之前不知道该聚为几类，该如何确定最佳的k值呢？</p>
<p>​        常用的有三种方式：<code>簇内离差平方和拐点法</code>、<code>轮廓系数法</code>、<code>间隔统计量法</code>。</p>
<h4 id="拐点法"><a href="#拐点法" class="headerlink" title="拐点法"></a>拐点法</h4><p>​        拐点法比较简单，类似于PCA降维时通过绘制贡献率曲线决定维数。通过可视化方法找到”拐点“对应的k值。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入第三方包</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np  </span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"></span><br><span class="line"><span class="comment"># 随机生成三组二元正态分布随机数 </span></span><br><span class="line">np.random.seed(<span class="number">1234</span>)</span><br><span class="line">mean1 = [<span class="number">0.5</span>, <span class="number">0.5</span>]</span><br><span class="line">cov1 = [[<span class="number">0.3</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0.3</span>]]</span><br><span class="line">x1, y1 = np.random.multivariate_normal(mean1, cov1, <span class="number">1000</span>).T</span><br><span class="line"></span><br><span class="line">mean2 = [<span class="number">0</span>, <span class="number">8</span>]</span><br><span class="line">cov2 = [[<span class="number">1.5</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">1</span>]]</span><br><span class="line">x2, y2 = np.random.multivariate_normal(mean2, cov2, <span class="number">1000</span>).T</span><br><span class="line"></span><br><span class="line">mean3 = [<span class="number">8</span>, <span class="number">4</span>]</span><br><span class="line">cov3 = [[<span class="number">1.5</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">1</span>]]</span><br><span class="line">x3, y3 = np.random.multivariate_normal(mean3, cov3, <span class="number">1000</span>).T</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制三组数据的散点图</span></span><br><span class="line">plt.scatter(x1,y1)</span><br><span class="line">plt.scatter(x2,y2)</span><br><span class="line">plt.scatter(x3,y3)</span><br><span class="line"><span class="comment"># 显示图形</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 构造自定义函数，用于绘制不同k值和对应总的簇内离差平方和的折线图</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">k_SSE</span><span class="params">(X, clusters)</span>:</span></span><br><span class="line">    <span class="comment"># 选择连续的K种不同的值</span></span><br><span class="line">    K = range(<span class="number">1</span>,clusters+<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 构建空列表用于存储总的簇内离差平方和</span></span><br><span class="line">    TSSE = []</span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> K:</span><br><span class="line">        <span class="comment"># 用于存储各个簇内离差平方和</span></span><br><span class="line">        SSE = []</span><br><span class="line">        kmeans = KMeans(n_clusters=k)</span><br><span class="line">        kmeans.fit(X)</span><br><span class="line">        <span class="comment"># 返回簇标签</span></span><br><span class="line">        labels = kmeans.labels_</span><br><span class="line">        <span class="comment"># 返回簇中心</span></span><br><span class="line">        centers = kmeans.cluster_centers_</span><br><span class="line">        <span class="comment"># 计算各簇样本的离差平方和，并保存到列表中</span></span><br><span class="line">        <span class="keyword">for</span> label <span class="keyword">in</span> set(labels):</span><br><span class="line">            SSE.append(np.sum((X.loc[labels == label,]-centers[label,:])**<span class="number">2</span>))</span><br><span class="line">        <span class="comment"># 计算总的簇内离差平方和 </span></span><br><span class="line">        TSSE.append(np.sum(SSE))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 中文和负号的正常显示</span></span><br><span class="line">    plt.rcParams[<span class="string">'font.sans-serif'</span>] = [<span class="string">'Microsoft YaHei'</span>]</span><br><span class="line">    plt.rcParams[<span class="string">'axes.unicode_minus'</span>] = <span class="literal">False</span></span><br><span class="line">    <span class="comment"># 设置绘图风格</span></span><br><span class="line">    plt.style.use(<span class="string">'ggplot'</span>)</span><br><span class="line">    <span class="comment"># 绘制K的个数与GSSE的关系</span></span><br><span class="line">    plt.plot(K, TSSE, <span class="string">'b*-'</span>)</span><br><span class="line">    plt.xlabel(<span class="string">'簇的个数'</span>)</span><br><span class="line">    plt.ylabel(<span class="string">'簇内离差平方和之和'</span>)</span><br><span class="line">    <span class="comment"># 显示图形</span></span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将三组数据集汇总到数据框中</span></span><br><span class="line">X = pd.DataFrame(np.concatenate([np.array([x1,y1]),np.array([x2,y2]),np.array([x3,y3])], axis = <span class="number">1</span>).T)</span><br><span class="line"><span class="comment"># 自定义函数的调用</span></span><br><span class="line">k_SSE(X, <span class="number">15</span>)</span><br></pre></td></tr></table></figure>
<h4 id="轮廓系数法"><a href="#轮廓系数法" class="headerlink" title="轮廓系数法"></a>轮廓系数法</h4><p>​        该方法综合考虑了<code>簇的密集性</code>与<code>分散性</code>两个信息，即数据集被划分为k个簇，簇内高密集，簇间高分散。轮廓系数的计算方式：</p>
<script type="math/tex; mode=display">
S(i)=\frac {b(i)-a(i)}{max(a(i),b(i))}</script><p>​        其中，$a(i)$——簇内的密集性，代表样本i与同簇内其他样本点距离的平均值；</p>
<p>​        $b(i)$——簇间的分散性，计算过程，样本i与其他非同簇样本点距离的平均值，然后从平均值中挑选出最小值。</p>
<p>​        当$S(i)$接近于-1，说明样本分配的不合理，需要将其分配到其他簇；</p>
<p>​        当$S(i)$近似为0，说明样本处于模糊地带，即簇的边界；</p>
<p>​        当$S(i)$近似为1，说明样本i分配的合理。</p>
<p>​        <strong>可以看出$S(i)$仅仅是计算单个样本i的轮廓系数，最后需要对所有点的轮廓系数求均值，才是对应k个簇的总轮廓系数</strong>。</p>
<p>​        当总轮廓系数小于0时，说明聚类效果不佳；</p>
<p>​        当总轮廓系数接近于1时，说明簇内样本的平均距离a非常小，簇间距离b非常大，聚类合理。</p>
<p>​        <code>sklearn</code>中对应模块：<code>metrices中的silhouette_score</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 构造自定义函数，用于绘制不同k值和对应轮廓系数的折线图</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">k_silhouette</span><span class="params">(X, clusters)</span>:</span></span><br><span class="line">    K = range(<span class="number">2</span>,clusters+<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 构建空列表，用于存储个中簇数下的轮廓系数</span></span><br><span class="line">    S = []</span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> K:</span><br><span class="line">        kmeans = KMeans(n_clusters=k)</span><br><span class="line">        kmeans.fit(X)</span><br><span class="line">        labels = kmeans.labels_</span><br><span class="line">        <span class="comment"># 调用字模块metrics中的silhouette_score函数，计算轮廓系数</span></span><br><span class="line">        S.append(metrics.silhouette_score(X, labels, metric=<span class="string">'euclidean'</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 中文和负号的正常显示</span></span><br><span class="line">    plt.rcParams[<span class="string">'font.sans-serif'</span>] = [<span class="string">'Microsoft YaHei'</span>]</span><br><span class="line">    plt.rcParams[<span class="string">'axes.unicode_minus'</span>] = <span class="literal">False</span></span><br><span class="line">    <span class="comment"># 设置绘图风格</span></span><br><span class="line">    plt.style.use(<span class="string">'ggplot'</span>)    </span><br><span class="line">    <span class="comment"># 绘制K的个数与轮廓系数的关系</span></span><br><span class="line">    plt.plot(K, S, <span class="string">'b*-'</span>)</span><br><span class="line">    plt.xlabel(<span class="string">'簇的个数'</span>)</span><br><span class="line">    plt.ylabel(<span class="string">'轮廓系数'</span>)</span><br><span class="line">    <span class="comment"># 显示图形</span></span><br><span class="line">    plt.show()</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 自定义函数的调用</span></span><br><span class="line">k_silhouette(X, <span class="number">15</span>)</span><br></pre></td></tr></table></figure>
<h4 id="间隔统计量法"><a href="#间隔统计量法" class="headerlink" title="间隔统计量法"></a>间隔统计量法</h4><p>​        该方法适用于任何聚类算法。</p>
<p>​        Gap Statistic方法就是通过比较参照数据集的期望和实际数据集的对数，找到其下降最快的k值。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 自定义函数，计算簇内任意两样本之间的欧氏距离</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">short_pair_wise_D</span><span class="params">(each_cluster)</span>:</span></span><br><span class="line">    mu = each_cluster.mean(axis = <span class="number">0</span>)</span><br><span class="line">    Dk = sum(sum((each_cluster - mu)**<span class="number">2</span>)) * <span class="number">2.0</span> * each_cluster.shape[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">return</span> Dk</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算簇内的Wk值</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_Wk</span><span class="params">(data, classfication_result)</span>:</span></span><br><span class="line">    Wk = <span class="number">0</span></span><br><span class="line">    label_set = set(classfication_result)</span><br><span class="line">    <span class="keyword">for</span> label <span class="keyword">in</span> label_set:</span><br><span class="line">        each_cluster = data[classfication_result == label, :]</span><br><span class="line">        Wk = Wk + short_pair_wise_D(each_cluster)/(<span class="number">2.0</span>*each_cluster.shape[<span class="number">0</span>])</span><br><span class="line">    <span class="keyword">return</span> Wk</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算GAP统计量 </span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gap_statistic</span><span class="params">(X, B=<span class="number">10</span>, K=range<span class="params">(<span class="number">1</span>,<span class="number">11</span>)</span>, N_init = <span class="number">10</span>)</span>:</span></span><br><span class="line">    <span class="comment"># 将输入数据集转换为数组</span></span><br><span class="line">    X = np.array(X)</span><br><span class="line">    <span class="comment"># 生成B组参照数据</span></span><br><span class="line">    shape = X.shape</span><br><span class="line">    tops = X.max(axis=<span class="number">0</span>)</span><br><span class="line">    bots = X.min(axis=<span class="number">0</span>)</span><br><span class="line">    dists = np.matrix(np.diag(tops-bots))</span><br><span class="line">    rands = np.random.random_sample(size=(B,shape[<span class="number">0</span>],shape[<span class="number">1</span>]))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(B):</span><br><span class="line">        rands[i,:,:] = rands[i,:,:]*dists+bots</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 自定义0元素的数组，用于存储gaps、Wks和Wkbs</span></span><br><span class="line">    gaps = np.zeros(len(K))</span><br><span class="line">    Wks = np.zeros(len(K))</span><br><span class="line">    Wkbs = np.zeros((len(K),B))</span><br><span class="line">    <span class="comment"># 循环不同的k值，</span></span><br><span class="line">    <span class="keyword">for</span> idxk, k <span class="keyword">in</span> enumerate(K):</span><br><span class="line">        k_means =  KMeans(n_clusters=k)</span><br><span class="line">        k_means.fit(X)</span><br><span class="line">        classfication_result = k_means.labels_</span><br><span class="line">        <span class="comment"># 将所有簇内的Wk存储起来</span></span><br><span class="line">        Wks[idxk] = compute_Wk(X,classfication_result)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 通过循环，计算每一个参照数据集下的各簇Wk值</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(B):</span><br><span class="line">            Xb = rands[i,:,:]</span><br><span class="line">            k_means.fit(Xb)</span><br><span class="line">            classfication_result_b = k_means.labels_</span><br><span class="line">            Wkbs[idxk,i] = compute_Wk(Xb,classfication_result_b)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算gaps、sd_ks、sk和gapDiff</span></span><br><span class="line">    gaps = (np.log(Wkbs)).mean(axis = <span class="number">1</span>) - np.log(Wks)        </span><br><span class="line">    sd_ks = np.std(np.log(Wkbs), axis=<span class="number">1</span>)</span><br><span class="line">    sk = sd_ks*np.sqrt(<span class="number">1</span>+<span class="number">1.0</span>/B)</span><br><span class="line">    <span class="comment"># 用于判别最佳k的标准，当gapDiff首次为正时，对应的k即为目标值</span></span><br><span class="line">    gapDiff = gaps[:<span class="number">-1</span>] - gaps[<span class="number">1</span>:] + sk[<span class="number">1</span>:]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 中文和负号的正常显示</span></span><br><span class="line">    plt.rcParams[<span class="string">'font.sans-serif'</span>] = [<span class="string">'Microsoft YaHei'</span>]</span><br><span class="line">    plt.rcParams[<span class="string">'axes.unicode_minus'</span>] = <span class="literal">False</span></span><br><span class="line">    <span class="comment"># 设置绘图风格</span></span><br><span class="line">    plt.style.use(<span class="string">'ggplot'</span>)</span><br><span class="line">    <span class="comment"># 绘制gapDiff的条形图</span></span><br><span class="line">    plt.bar(np.arange(len(gapDiff))+<span class="number">1</span>, gapDiff, color = <span class="string">'steelblue'</span>)</span><br><span class="line">    plt.xlabel(<span class="string">'簇的个数'</span>)</span><br><span class="line">    plt.ylabel(<span class="string">'k的选择标准'</span>)</span><br><span class="line">    plt.show()</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 自定义函数的调用</span></span><br><span class="line">gap_statistic(X)</span><br></pre></td></tr></table></figure>
<hr>
<p>​        上述三种方法判断合理的k值方法为：</p>
<p>​        <code>拐点法</code>：找到斜率变化最大的那个k；</p>
<p>​        <code>轮廓系数法</code>：找到曲线最高、最接近1的k；</p>
<p>​        <code>间隔统计量法</code>：找到gapdiff首次出现正值的k。</p>
<h3 id="Kmeans聚类的注意点"><a href="#Kmeans聚类的注意点" class="headerlink" title="Kmeans聚类的注意点"></a>Kmeans聚类的注意点</h3><p>​        在做Kmeans聚类时<strong>注意</strong>：</p>
<p>​        1）聚类前必须指定具体的簇数k值；</p>
<p>​        2）对原始数据集做必要的标准化处理，如果原始数据集在量纲上存在差异，就必须标准化，否则不需要；</p>
<p>​        3）如果数据集中有离散型的字符型变量，需要对该变量做预处理，比如设置哑变量或转换成数值化的因子。</p>
<p>​        可以借助<code>seaborn</code>的<code>lmplot</code>方法绘制聚类效果的散点图；为了直观对比k个簇内样本之间的差异，可以使用雷达图对各个维度的信息进行展现。雷达图的绘制需要<code>pygal</code>模块，调用<code>Radar</code>类。</p>
<h3 id="手动实现Kmeans聚类算法"><a href="#手动实现Kmeans聚类算法" class="headerlink" title="手动实现Kmeans聚类算法"></a>手动实现Kmeans聚类算法</h3><h4 id="构建距离计算函数"><a href="#构建距离计算函数" class="headerlink" title="构建距离计算函数"></a>构建距离计算函数</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#样本点和簇中心的距离计算</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">distEclud</span><span class="params">(arrA,arrB)</span>:</span></span><br><span class="line">    dist=np.sum(np.power(arrA-arrB,<span class="number">2</span>),axis=<span class="number">1</span>)<span class="comment">#这里用平方和代替距离，简化计算</span></span><br><span class="line">    <span class="keyword">return</span> dist</span><br></pre></td></tr></table></figure>
<h4 id="随机初始簇心"><a href="#随机初始簇心" class="headerlink" title="随机初始簇心"></a>随机初始簇心</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#生成随机簇中心</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">randCent</span><span class="params">(dataSet,k)</span>:</span></span><br><span class="line">    n=dataSet.shape[<span class="number">1</span>]<span class="comment">#获取数据集的特征数</span></span><br><span class="line">    data_min=dataSet.iloc[:,:].min()<span class="comment">#获取每一列特征的最小值</span></span><br><span class="line">    data_max=dataSer.iloc[:,:].max()<span class="comment">#获取每一列特征的最大值</span></span><br><span class="line">    data_cent=np.random.uniform(data_min,data_max,(k,n))<span class="comment">#生成取值范围内的随机数，k行n列，即初始簇中心</span></span><br><span class="line">    <span class="keyword">return</span> data_cent</span><br></pre></td></tr></table></figure>
<h4 id="Kmeans聚类算法"><a href="#Kmeans聚类算法" class="headerlink" title="Kmeans聚类算法"></a>Kmeans聚类算法</h4><p>​        在执行Kmeans聚类算法时，需要不断地迭代质心，因此需要两个可迭代容器来完成该目标。</p>
<p>​        第一个容器用于存放和更新质心，该容器可考虑使用list来执行，list不仅是可迭代对象，同时list内不同元素索引位置也可用于标记和区分各质心，即各簇的编号；</p>
<p>​        第二个容器则需要记录、保存和更新各点到质心之间的距离，并能够方便对其进行比较，该容器由有3列的数组来执行。</p>
<p>​            <strong>第一列用于存放最近一次计算完成后某点到各质心的最短距离；</strong></p>
<p>​            <strong>第二列用于计算完成后根据最短距离得到的代表对应质心的数值索引，即所属簇，即质心的编号；</strong></p>
<p>​            <strong>第三列用于存放上一次对应的质心编号；</strong></p>
<p>​        后两列用于比较质心发生变化后某点所属簇的情况是否发生变化。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Kmeans聚类算法</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">KMeans</span><span class="params">(dataSet,k,distMeas=distEclud,createCent=randCent)</span>:</span></span><br><span class="line">    m,n=dataSet.shape</span><br><span class="line">    centroids=createCent(dataSet,k)<span class="comment">#生成k个质心</span></span><br><span class="line">    clusterAssment=np.zeros((m,<span class="number">3</span>))<span class="comment">#容器2</span></span><br><span class="line">    clusterAssment[:,<span class="number">0</span>]=np.inf<span class="comment">#存放无穷大值</span></span><br><span class="line">    clusterAssment[:,<span class="number">1</span>:<span class="number">3</span>]=<span class="number">-1</span><span class="comment">#存放-1作为初始值</span></span><br><span class="line">    <span class="comment">#连接原始数据集和容器2</span></span><br><span class="line">    result_set=pd.concat([dataSet,pd.DataFrame(clusterAssment)],axis=<span class="number">1</span>,ignore_index=<span class="literal">True</span>)</span><br><span class="line">    clusterChanged=<span class="literal">True</span></span><br><span class="line">    <span class="keyword">while</span> clusterChanged:</span><br><span class="line">        clusterChanged=<span class="literal">False</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">            dist=distMeas(dataSet.iloc[i,:].values,centroids)<span class="comment">#计算样本点与所有初始质心的距离</span></span><br><span class="line">            result_set.iloc[i,n]=dist.min()<span class="comment">#获取与所有质心的距离中最小的一个</span></span><br><span class="line">            <span class="comment">#获取最小距离的索引,其实此时的索引就是特征索引值</span></span><br><span class="line">            result_set.iloc[i,n+<span class="number">1</span>]=np.where(dist==dist.min())[<span class="number">0</span>]</span><br><span class="line">         <span class="comment">#只有当所有质心都与上次相同</span></span><br><span class="line">        clusterChanged=<span class="keyword">not</span> (result_set.iloc[:,<span class="number">-1</span>]==result_set.iloc[:,<span class="number">-2</span>]).all()</span><br><span class="line">        <span class="keyword">if</span> clusterChanged:</span><br><span class="line">            cent_df=result_set.grouby(n+<span class="number">1</span>).mean()<span class="comment">#各个簇分组统计均值</span></span><br><span class="line">            centroids=cen_df.iloc[:,:n].values<span class="comment">#用簇中所有点的均值作为质心</span></span><br><span class="line">            result_set.iloc[:,<span class="number">-1</span>]=result_set.iloc[:,<span class="number">-2</span>]<span class="comment">#将索引更新</span></span><br><span class="line">    <span class="keyword">return</span> centroids,result_set</span><br></pre></td></tr></table></figure>
<p>​        在聚类结束之后，可以查看最后一列查看分类情况，如：<code>result.iloc[:,-1].value_counts()</code>。</p>
<p>​        </p>
<h4 id="误差平方和"><a href="#误差平方和" class="headerlink" title="误差平方和"></a>误差平方和</h4><p>​        误差平方和（SSE）是聚类算法模型最重要评估指标。</p>
<p>​        对于聚类算法而言，误差平方和仍然有一定的局限性，主要体现在以下几点：</p>
<ul>
<li><p>对于任意数据集而言，聚类误差平方和和质心数量高度相关，随着质心增加，误差平方和将逐渐下降；</p>
</li>
<li><p>误差平方和还与数据集本身数据量大小、量纲大小、数据维度高度相关，数据量越大、量纲越大、维度越高则在相同质心数量情况下误差平方和也将更大。</p>
</li>
</ul>
<p>​        增加簇的个数肯定可以降低SSE值，但这违背了聚类的目标，即在保持簇的数据不变的情况下，提高簇的质量。</p>
<p>​        因此，模型误差平方和没有绝对意义，比较不同数据集聚类结果的误差平方和没有任何意义，误差平方和在聚类分析中主要作用有以下两点：</p>
<ul>
<li><p>确定模型最优化目标，结合距离计算方法进而推导质心选取方法；</p>
</li>
<li><p>对于确定数据集可绘制横轴为质心数量、纵轴为误差平方和的曲线，可以判断，曲线整体将呈现下降趋势，其实就是上面所说的”拐点法”。</p>
</li>
</ul>
<p>​        </p>
<h4 id="使用后处理来提高聚类性能"><a href="#使用后处理来提高聚类性能" class="headerlink" title="使用后处理来提高聚类性能"></a>使用后处理来提高聚类性能</h4><p>​        对生成的簇进行后处理，一种方法是将最大的SSE值的簇划分为两个簇。具体实现时可以将最大簇包含的点过滤出来并在这些点上运行Kmeans聚类算法，k设为2。</p>
<p>​        由于为了保持簇的总数不变，上面拆分变成两个簇，就需要将某两个簇合并成一个簇，有两种可以量化的方法：合并最近的质心，或者合并两个是的SSE增幅最小的质心。</p>
<ol>
<li>通过计算所有质心之间的距离，然后合并距离最近的两个点来实现。</li>
<li>合并两个簇然后计算总的SSE值。</li>
</ol>
<p>​        必须在所有可能的两个簇上重复上述处理的过程，直到找到合并最佳的两个簇为止。这就是后面即将提到的“二分 Kmeans算法”。</p>
<h4 id="存在的问题"><a href="#存在的问题" class="headerlink" title="存在的问题"></a>存在的问题</h4><p>​        随机初始质心对最终的聚类结果是有影响的，所以尽量降低初始化质心的随机性对最后聚类结果造成影响，方案有以下几种：</p>
<p>​        1）在初始化质心随机生成的过程中，尽可能的让质心更加分散</p>
<p>​            这点其实在利用<code>np.random.random</code>进行[0,1)区间取均匀分布抽样而不是进行随机抽样。</p>
<p>​        2）人工制定初始质心</p>
<p>​            即在观察数据集分布情况后，手工设置初始质心，此举也能降低随机性影响。</p>
<p>​        3）增量的更新质心</p>
<p>​            </p>
<h3 id="二分Kmeans算法"><a href="#二分Kmeans算法" class="headerlink" title="二分Kmeans算法"></a>二分Kmeans算法</h3><p>​        为克服Kmeans算法收敛于局部最小值的问题，提出二分Kmeans算法，该算法的思路是，首先将所有点看作一个簇，然后一分为二。之后选择其中一个簇继续进行划分，选择哪一个簇进行划分取决于对其划分是否可以最大程度降低SSE值，直到得到用户指定的簇数目为止。</p>
<p>​        另一种做法是选择SSE最大的簇进行划分，直到簇数据达到k为止。</p>
<p>​                        </p>
<p>​                    </p>
<h3 id="相关阅读"><a href="#相关阅读" class="headerlink" title="相关阅读"></a>相关阅读</h3><p>​        （1）<a href="https://www.cnblogs.com/mfryf/p/9007524.html" target="_blank" rel="noopener">机器学习sklearn19.0聚类算法——Kmeans算法</a></p>
<p>​        （2）从零开始学Python数据分析与挖掘</p>
<p>​        （3）机器学习实战</p>
<p>​        （4）<a href="https://www.bilibili.com/video/av39246256" target="_blank" rel="noopener">菊安酱的机器学习  第9期 Kmeans聚类</a></p>

      
    </div>

    
      

  <div class="popular-posts-header">相关文章推荐</div>
  <ul class="popular-posts">
  
    <li class="popular-posts-item">
      
      
      <div class="popular-posts-title"><a href="\2019\10\04\PCA\" rel="bookmark">机器学习—降维</a></div>
      
    </li>
  
    <li class="popular-posts-item">
      
      
      <div class="popular-posts-title"><a href="\2019\09\30\LineRegression\" rel="bookmark">机器学习-线性回归</a></div>
      
    </li>
  
  </ul>


    

    <div>
      
        <div>
    
        <div style="text-align:center;color: #FA8072;font-size:12px;">------------- EOF <i class="fa fa-hourglass-end" aria-hidden="true"></i> -------------</div>
    
</div>
      
    </div>

    
    
    

    

    
      
    
    

    
      <div>
        




  



<ul class="post-copyright">
  <li class="post-copyright-title">
    <strong>本文标题：</strong>机器学习—Kmeans聚类</li>
  <li class="post-copyright-author">
    <strong>文章作者： </strong>小木子</li>
  <li class="post-copyright-link">
    <strong>原始链接：</strong>
    
    <a href="https://ligang-chn.github.io/2019/10/03/Kmeans聚类/" title="机器学习—Kmeans聚类">https://ligang-chn.github.io/2019/10/03/Kmeans聚类/</a>
  </li>
  <li class="post-copyright-license">
    <strong>许可协议： </strong>本文章采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/zh-CN" rel="noopener" target="_blank"><i class="fa fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议，转载请保留原文链接及作者。</li>
</ul>

      </div>
    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Python/" rel="tag"><i class="fa fa-tag"></i> Python</a>
          
            <a href="/tags/聚类/" rel="tag"><i class="fa fa-tag"></i> 聚类</a>
          
            <a href="/tags/KMeans/" rel="tag"><i class="fa fa-tag"></i> KMeans</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/10/02/弄清相对路径/" rel="next" title="弄清相对路径">
                <i class="fa fa-chevron-left"></i> 弄清相对路径
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/10/04/PCA/" rel="prev" title="机器学习—降维">
                机器学习—降维 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>


  </div>


          </div>
          

  
    <div class="comments" id="comments">
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
            <a href="/">
              <img class="site-author-image" itemprop="image" src="/images/avatar.png" alt="小木子">
            </a>
            
              <p class="site-author-name" itemprop="name">小木子</p>
              <div class="site-description motion-element" itemprop="description">拥抱月亮</div>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">14</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  
                    
                      <a href="/categories/">
                    
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">5</span>
                    <span class="site-state-item-name">分类</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  
                    
                      <a href="/tags/">
                    
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">18</span>
                    <span class="site-state-item-name">标签</span>
                  </a>
                </div>
              
            </nav>
          

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          

          
            <div class="links-of-author motion-element">
              
                <span class="links-of-author-item">
                  
                  
                  
                    
                  
                  <a href="https://github.com/ligang-chn" title="GitHub &rarr; https://github.com/ligang-chn" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i></a>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                  
                    
                  
                  <a href="mailto:ligang_chn@163.com" title="E-Mail &rarr; mailto:ligang_chn@163.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i></a>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                  
                    
                  
                  <a href="https://weibo.com/5318639612/profile?rightmod=1&wvr=6&mod=personinfo" title="Weibo &rarr; https://weibo.com/5318639612/profile?rightmod=1&wvr=6&mod=personinfo" rel="noopener" target="_blank"><i class="fa fa-fw fa-weibo"></i></a>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                  
                    
                  
                  <a href="https://blog.csdn.net/weixin_43343803" title="CSDN &rarr; https://blog.csdn.net/weixin_43343803" rel="noopener" target="_blank"><i class="fa fa-fw fa-eercast"></i></a>
                </span>
              
            </div>
          

          
          <!-- 添加近期文章 -->
          
             <div class="links-of-blogroll motion-element links-of-blogroll-block">
              <div class="links-of-blogroll-title">
                <!-- modify icon to fire by szw -->
                <i class="fa fa-history fa-" aria-hidden="true"></i>
                近期文章
              </div>
              <ul class="links-of-blogroll-list">
                
                
                  <li>
                    <a href="/2019/10/07/QtQSS/" title="Qt—QSS样式表" target="_blank">Qt—QSS样式表</a>
                  </li>
                
                  <li>
                    <a href="/2019/10/07/QtQString/" title="QString&QByteArray&QVariant" target="_blank">QString&QByteArray&QVariant</a>
                  </li>
                
                  <li>
                    <a href="/2019/10/05/datastructureList/" title="线性表" target="_blank">线性表</a>
                  </li>
                
                  <li>
                    <a href="/2019/10/04/PCA/" title="机器学习—降维" target="_blank">机器学习—降维</a>
                  </li>
                
                  <li>
                    <a href="/2019/10/03/Kmeans聚类/" title="机器学习—Kmeans聚类" target="_blank">机器学习—Kmeans聚类</a>
                  </li>
                
              </ul>
            </div>
          

          
             <div class="cc-license motion-element" itemprop="license">
              
              
                
              
              
              
              <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/zh-CN" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a>
             </div>
          

      <iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="86" src="//music.163.com/outchain/player?type=2&id=38592976&auto=0&height=66"></iframe>


          
          

          
            
          
          

        </div>
      </div>

      
      <!--noindex-->
        <div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
            
            
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#Kmeans的思想"><span class="nav-number">1.</span> <span class="nav-text">Kmeans的思想</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Kmeans的原理"><span class="nav-number">2.</span> <span class="nav-text">Kmeans的原理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#K值确定"><span class="nav-number">3.</span> <span class="nav-text">K值确定</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#拐点法"><span class="nav-number">3.1.</span> <span class="nav-text">拐点法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#轮廓系数法"><span class="nav-number">3.2.</span> <span class="nav-text">轮廓系数法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#间隔统计量法"><span class="nav-number">3.3.</span> <span class="nav-text">间隔统计量法</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Kmeans聚类的注意点"><span class="nav-number">4.</span> <span class="nav-text">Kmeans聚类的注意点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#手动实现Kmeans聚类算法"><span class="nav-number">5.</span> <span class="nav-text">手动实现Kmeans聚类算法</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#构建距离计算函数"><span class="nav-number">5.1.</span> <span class="nav-text">构建距离计算函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#随机初始簇心"><span class="nav-number">5.2.</span> <span class="nav-text">随机初始簇心</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Kmeans聚类算法"><span class="nav-number">5.3.</span> <span class="nav-text">Kmeans聚类算法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#误差平方和"><span class="nav-number">5.4.</span> <span class="nav-text">误差平方和</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#使用后处理来提高聚类性能"><span class="nav-number">5.5.</span> <span class="nav-text">使用后处理来提高聚类性能</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#存在的问题"><span class="nav-number">5.6.</span> <span class="nav-text">存在的问题</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#二分Kmeans算法"><span class="nav-number">6.</span> <span class="nav-text">二分Kmeans算法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#相关阅读"><span class="nav-number">7.</span> <span class="nav-text">相关阅读</span></a></li></ol></div>
            

          </div>
        </div>
      <!--/noindex-->
      



      

    </div>
  </aside>
  


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">LIGANG</span>

  <span class="post-meta-divider footer-ages-icon"> | </span>

  

  
</div>











        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      我的第 <span class="busuanzi-value" id="busuanzi_value_site_uv"></span> 位朋友，
    </span>
  

  
    <span class="site-pv">
      历经 <span class="busuanzi-value" id="busuanzi_value_site_pv"></span> 次回眸才与你相遇
    </span>
  

</div>









        
        <div class="footer-custom">
            
          
          
        </div>
        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
          <span id="scrollpercent"><span>0</span>%</span>
        
      </div>
    

    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>












  





  
  











  
  <script src="//cdn.jsdelivr.net/npm/jquery@2.1.3/dist/jquery.min.js"></script>

  
  <script src="//cdn.jsdelivr.net/npm/velocity-animate@1/velocity.min.js"></script>

  
  <script src="//cdn.jsdelivr.net/npm/velocity-animate@1/velocity.ui.min.js"></script>

  
  <script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script>

  
  <script src="/lib/three/three.min.js"></script>

  
  <script src="/lib/three/three-waves.min.js"></script>


  


  <script src="/js/utils.js?v=7.1.0"></script>

  <script src="/js/motion.js?v=7.1.0"></script>



  
  


  <script src="/js/schemes/muse.js?v=7.1.0"></script>



  
  <script src="/js/scrollspy.js?v=7.1.0"></script>
<script src="/js/post-details.js?v=7.1.0"></script>



  


  <script src="/js/next-boot.js?v=7.1.0"></script>


  

  

  

  
  

  

<script src="//cdn.jsdelivr.net/npm/leancloud-storage@3/dist/av-min.js"></script>



  

<script src="//cdn.jsdelivr.net/npm/valine@1/dist/Valine.min.js"></script>

<script>
  var GUEST = ['nick', 'mail', 'link'];
  var guest = 'nick,mail';
  guest = guest.split(',').filter(function(item) {
    return GUEST.indexOf(item) > -1;
  });
  new Valine({
    el: '#comments',
    verify: false,
    notify: false,
    appId: 'DtNyggQIc9MXElGj7h71pBAc-gzGzoHsz',
    appKey: 'jW0GEGzm4eiW9WJyUGABxw5t',
    placeholder: '不想和我聊点什么？',
    avatar: 'mm',
    meta: guest,
    pageSize: '10' || 10,
    visitor: true,
    lang: 'zh-cn' || 'zh-cn'
  });
</script>




  


  
  <script>
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url).replace(/\/{2,}/g, '/');
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('5');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x"></i></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x"></i></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  
  

  
  

  
    
      <script type="text/x-mathjax-config">
  

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });
  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') { next = next.nextSibling }
        if (next && next.nodeName.toLowerCase() === 'br') { next.parentNode.removeChild(next) }
      }
    });
  });
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      document.getElementById(all[i].inputID + '-Frame').parentNode.className += ' has-jax';
    }
  });
</script>
<script src="//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

    
  


  

  

  
  <script>
    (function(){
      var bp = document.createElement('script');
      var curProtocol = window.location.protocol.split(':')[0];
      bp.src = (curProtocol === 'https') ? 'https://zz.bdstatic.com/linksubmit/push.js' : 'http://push.zhanzhang.baidu.com/push.js';
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(bp, s);
    })();
  </script>


  

  

  

  
  
  
    
  
  <script src="//cdn.jsdelivr.net/npm/pangu@4/dist/browser/pangu.min.js"></script>
  <script>pangu.spacingPage();</script>


  

  
<script>
  $('.highlight').each(function(i, e) {
    var $wrap = $('<div>').addClass('highlight-wrap');
    $(e).after($wrap);
    $wrap.append($('<button>').addClass('copy-btn').append('复制').on('click', function(e) {
      var code = $(this).parent().find('.code').find('.line').map(function(i, e) {
        return $(e).text();
      }).toArray().join('\n');
      var ta = document.createElement('textarea');
      var yPosition = window.pageYOffset || document.documentElement.scrollTop;
      ta.style.top = yPosition + 'px'; // Prevent page scroll
      ta.style.position = 'absolute';
      ta.style.opacity = '0';
      ta.readOnly = true;
      ta.value = code;
      document.body.appendChild(ta);
      ta.select();
      ta.setSelectionRange(0, code.length);
      ta.readOnly = false;
      var result = document.execCommand('copy');
      
        if (result) $(this).text('复制成功');
        else $(this).text('复制失败');
      
      ta.blur(); // For iOS
      $(this).blur();
    })).on('mouseleave', function(e) {
      var $b = $(this).find('.copy-btn');
      setTimeout(function() {
        $b.text('复制');
      }, 300);
    }).append(e);
  })
</script>


  

  


   
<script>
  $(document).ready(function () {
    $(".header-inner").animate({padding: "25px 0 25px"}, 1000);
  });
</script>


  
    <script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/moment.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/moment-precise-range-plugin@1.3.0/moment-precise-range.min.js"></script>
    <script>
      function timer() {
        var ages = moment.preciseDiff(moment(),moment(20190930,"YYYYMMDD"));
        ages = ages.replace(/\s?\d{0,2}\s+hours?/, "");
        ages = ages.replace(/\s?\d{0,2}\s+minutes?/, "");
        ages = ages.replace(/\s?\d{0,2}\s+seconds?/, "");
        ages = ages.replace(/years?/, "年");
        ages = ages.replace(/months?/, "月");
        ages = ages.replace(/days?/, "天");
        ages = ages.replace(/\d+/g, '<span style="color:#1094e8">$&</span>');
        span.innerHTML = `我已在此等候你 ${ages}`;
      }
      var span = document.createElement("span");
      //插入到agesicon之后
      var agesicon = document.querySelector(".footer-ages-icon");
      document.querySelector(".copyright").insertBefore(span, agesicon.nextSibling);
      timer();
    </script>
  

<script type="text/javascript" src="/js/custom/hexo_resize_image.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-backstretch/2.0.4/jquery.backstretch.min.js"></script>
  <script>
    $("body").backstretch("https://github.com/ligang-chn/Blog_Back_Up/blob/master/source/chenyao.jpg");
  </script>
<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"live2d-widget-model-miku"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":false},"log":false});</script></body>
</html>
